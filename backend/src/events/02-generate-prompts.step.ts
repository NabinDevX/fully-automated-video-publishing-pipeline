import type { EventConfig, Handlers } from "motia";
import OpenAI from "openai";
import fs from "fs";
import path from "path";
import os from "os";
import { exec } from "child_process";
import { promisify } from "util";
import { pipeline } from "stream/promises";
import { getVideoStream } from "../shared/storage";

const execAsync = promisify(exec);

export const config: EventConfig = {
  name: "Generate-Prompts",
  type: "event",
  description: "Analyze video with Gemini AI and generate title, description & thumbnail prompts",
  flows: ["yt.video.upload"],
  subscribes: ["file.uploaded"],
  emits: [
    { topic: "prompts.generated", label: "Prompts Generated" },
    { topic: "prompts.generation.error", label: "Generation Error", conditional: true },
  ],
};

interface FileUploadedInput {
  traceId: string;
  fileName: string;
  mimetype: string;
  size: number;
  storageKey: string;
  url: string;
  format: string;
}

interface GeneratedContent {
  title: string;
  description: string;
  tags: string[];
  thumbnailPrompt: string;
  thumbnailStyle: string;
  thumbnailColors: string[];
  thumbnailTextOverlay: string;
}

export const handler: Handlers["Generate-Prompts"] = async (
  input: FileUploadedInput,
  { emit, logger, state }: any
) => {
  const { traceId, fileName, storageKey } = input;

  // Use OS temp directory for cross-platform compatibility
  const tempDir = path.join(os.tmpdir(), `video-analysis-${traceId}`);

  try {
    logger.info("Starting AI analysis and prompt generation", { traceId, fileName });

    // Get metadata from state
    const metadata = await state.get(traceId, "metadata");

    if (!metadata) {
      throw new Error("Metadata not found in state");
    }

    // Update status to processing
    await state.set(traceId, "status", {
      status: "analyzing-video",
      updatedAt: new Date().toISOString(),
    });

    // Check Gemini API key
    const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
    if (!GEMINI_API_KEY) {
      throw new Error("GEMINI_API_KEY is not configured");
    }

    // Create temp directory
    fs.mkdirSync(tempDir, { recursive: true });

    logger.info("Downloading video from storage", { traceId, storageKey });

    // Download video to temp directory
    const videoPath = path.join(tempDir, "video.mp4");
    const videoStream = await getVideoStream(storageKey);
    await pipeline(videoStream, fs.createWriteStream(videoPath));

    logger.info("Extracting frames from video", { traceId });

    // Extract frames using ffmpeg (1 frame per second, max 10 frames)
    const framesDir = path.join(tempDir, "frames");
    fs.mkdirSync(framesDir, { recursive: true });

    try {
      await execAsync(
        `ffmpeg -i "${videoPath}" -vf "fps=1,scale=640:-1" -vframes 10 "${path.join(framesDir, "frame-%03d.jpg")}" -y`,
        { timeout: 60000 } // 60 second timeout
      );
    } catch (ffmpegError: any) {
      logger.warn("FFmpeg frame extraction failed, trying alternative method", {
        traceId,
        error: ffmpegError.message
      });

      // Try simpler ffmpeg command
      await execAsync(
        `ffmpeg -i "${videoPath}" -vf "select=eq(n\\,0)+eq(n\\,30)+eq(n\\,60)+eq(n\\,90)+eq(n\\,120)" -vsync vfr "${path.join(framesDir, "frame-%03d.jpg")}" -y`,
        { timeout: 60000 }
      );
    }

    // Get extracted frames
    const frames = fs
      .readdirSync(framesDir)
      .filter(f => f.startsWith("frame-") && f.endsWith(".jpg"))
      .sort()
      .slice(0, 5); // Use max 5 frames

    if (frames.length === 0) {
      throw new Error("No frames could be extracted from video. Ensure FFmpeg is installed.");
    }

    logger.info("Frames extracted successfully", { traceId, frameCount: frames.length });

    // Initialize OpenAI client with Gemini endpoint
    const openai = new OpenAI({
      apiKey: GEMINI_API_KEY,
      baseURL: "https://generativelanguage.googleapis.com/v1beta/openai/",
    });

    // Read frames and convert to base64
    const imageInputs = frames.map(frameName => {
      const framePath = path.join(framesDir, frameName);
      const imageBuffer = fs.readFileSync(framePath);
      const base64Image = imageBuffer.toString("base64");

      return {
        type: "image_url" as const,
        image_url: {
          url: `data:image/jpeg;base64,${base64Image}`,
        },
      };
    });

    // Build context from user metadata
    const userContext = {
      title: metadata.title || "",
      description: metadata.description || "",
      tags: metadata.tags || [],
      autoGenerateTitle: metadata.autoGenerateTitle !== false,
      autoGenerateDescription: metadata.autoGenerateDescription !== false,
    };

    logger.info("Sending frames to Gemini AI for analysis", { traceId, frameCount: frames.length });

    const prompt = `You are a YouTube content optimization expert. Analyze these video frames and generate optimized content.

${userContext.title ? `USER PROVIDED TITLE CONTEXT: ${userContext.title}` : ""}
${userContext.description ? `USER PROVIDED DESCRIPTION CONTEXT: ${userContext.description}` : ""}
${userContext.tags.length > 0 ? `USER PROVIDED TAGS: ${userContext.tags.join(", ")}` : ""}

TASKS:
1. Generate an engaging, SEO-optimized YouTube title (under 100 characters)
2. Generate a comprehensive YouTube description with keywords and call-to-action (200-500 words)
3. Generate 10-15 relevant tags for the video
4. Create a detailed thumbnail generation prompt for an AI image generator

THUMBNAIL REQUIREMENTS:
- Eye-catching and clickable design
- Professional YouTube thumbnail style (1280x720)
- Bright, contrasting colors that pop
- Include suggested text overlay (2-4 words max)
- Describe composition, lighting, and visual elements clearly

Respond ONLY with valid JSON in this exact format:
{
  "title": "Your generated title here",
  "description": "Your generated description here",
  "tags": ["tag1", "tag2", "tag3"],
  "thumbnailPrompt": "Detailed prompt describing the thumbnail scene, style, lighting, composition for AI image generation",
  "thumbnailStyle": "Style like cinematic, vibrant, minimalist, bold",
  "thumbnailColors": ["#FF0000", "#FFFFFF", "#000000"],
  "thumbnailTextOverlay": "2-4 word text for thumbnail"
}`;

    const response = await openai.chat.completions.create({
      model: "gemini-2.5-flash",
      messages: [
        {
          role: "user",
          content: [
            { type: "text", text: prompt },
            ...imageInputs,
          ],
        },
      ],
      temperature: 0.7,
      max_tokens: 2000,
    });

    const aiContent = response.choices[0]?.message?.content;

    if (!aiContent) {
      throw new Error("Empty response from Gemini AI");
    }

    logger.info("Received AI response", { traceId });

    // Parse the AI response - handle potential markdown code blocks
    let cleanedContent = aiContent.trim();

    // Remove markdown code blocks if present
    if (cleanedContent.startsWith("```json")) {
      cleanedContent = cleanedContent.slice(7);
    } else if (cleanedContent.startsWith("```")) {
      cleanedContent = cleanedContent.slice(3);
    }
    if (cleanedContent.endsWith("```")) {
      cleanedContent = cleanedContent.slice(0, -3);
    }
    cleanedContent = cleanedContent.trim();

    let generatedContent: GeneratedContent;
    try {
      generatedContent = JSON.parse(cleanedContent);
    } catch (parseError) {
      logger.error("Failed to parse AI response", { traceId, content: cleanedContent });
      throw new Error("Failed to parse AI response as JSON");
    }

    // Validate required fields
    if (!generatedContent.title) {
      throw new Error("AI response missing title");
    }
    if (!generatedContent.thumbnailPrompt) {
      throw new Error("AI response missing thumbnailPrompt");
    }

    // Build final content with defaults
    const finalContent: GeneratedContent = {
      title: userContext.autoGenerateTitle
        ? generatedContent.title
        : (userContext.title || generatedContent.title),
      description: userContext.autoGenerateDescription
        ? generatedContent.description
        : (userContext.description || generatedContent.description),
      tags: Array.isArray(generatedContent.tags) && generatedContent.tags.length > 0
        ? generatedContent.tags
        : (userContext.tags.length > 0 ? userContext.tags : ["video", "youtube"]),
      thumbnailPrompt: generatedContent.thumbnailPrompt,
      thumbnailStyle: generatedContent.thumbnailStyle || "vibrant",
      thumbnailColors: Array.isArray(generatedContent.thumbnailColors)
        ? generatedContent.thumbnailColors
        : ["#FF0000", "#FFFFFF", "#000000"],
      thumbnailTextOverlay: generatedContent.thumbnailTextOverlay || "",
    };

    // Store generated content in state
    await state.set(traceId, "generatedContent", {
      ...finalContent,
      generatedAt: new Date().toISOString(),
      model: "gemini-2.5-flash",
      framesAnalyzed: frames.length,
    });

    // Update metadata with final values
    await state.set(traceId, "metadata", {
      ...metadata,
      title: finalContent.title,
      description: finalContent.description,
      tags: finalContent.tags,
    });

    // Update status
    await state.set(traceId, "status", {
      status: "prompts-generated",
      updatedAt: new Date().toISOString(),
    });

    logger.info("AI content generated successfully", {
      traceId,
      title: finalContent.title,
      tagCount: finalContent.tags.length,
      hasThumbnailPrompt: Boolean(finalContent.thumbnailPrompt),
    });

    // Emit success event
    await emit({
      topic: "prompts.generated",
      data: {
        traceId,
        title: finalContent.title,
        description: finalContent.description,
        tags: finalContent.tags,
        thumbnailPrompt: finalContent.thumbnailPrompt,
        thumbnailStyle: finalContent.thumbnailStyle,
        thumbnailColors: finalContent.thumbnailColors,
        thumbnailTextOverlay: finalContent.thumbnailTextOverlay,
      },
    });

  } catch (error: any) {
    logger.error("Error generating prompts with AI", {
      traceId,
      error: error.message,
      stack: error.stack,
    });

    // Update status to failed
    try {
      await state.set(traceId, "status", {
        status: "prompt-generation-failed",
        error: error.message,
        updatedAt: new Date().toISOString(),
      });
    } catch {
      // Ignore state error
    }

    // Emit error event
    await emit({
      topic: "prompts.generation.error",
      data: {
        traceId,
        error: error.message,
        step: "generate-prompts",
      },
    });

  } finally {
    // Cleanup temp directory
    try {
      if (fs.existsSync(tempDir)) {
        fs.rmSync(tempDir, { recursive: true, force: true });
        logger.info("Cleaned up temp directory", { traceId });
      }
    } catch (cleanupError: any) {
      logger.warn("Failed to cleanup temp directory", {
        traceId,
        error: cleanupError.message
      });
    }
  }
};
